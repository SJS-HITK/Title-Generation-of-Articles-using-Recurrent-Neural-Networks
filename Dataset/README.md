## Dataset

There are two folders :

* ArXiv_Dataset - It contains the python notebook named arXiv_crawler.ipynb which collects data from [ArXiv](https://arxiv.org/) repository in a csv file and logs the results periodically
* Semantic_Scholar_Dataset - It contains a python notebook named Semantic_crawler.ipynb which collects data from [Semantic Scholar](https://www.semanticscholar.org/) Repository and stores in a CSV file

The data from the above two is combined and shuffled randomly to generate a compressed dataset file (link below) which is then further preprocessed using the file preprocessing.ipynb

> Please download this [dataset](https://drive.google.com/file/d/1_71U07k_cXUG9H7wPR5zQKavh-fzZbs-/view?usp=sharing) if needed and save anywhere locally in the same location as preprocessing.ipynb before running the code.
